{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Difference between name_scope and variable_scope:\n",
    "\n",
    "variable_scope facilitates variable sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use tf.get_variable():\n",
    "* first checks whether that variable exists\n",
    "* if it does, reuse it; otherwise, create a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# want the network to share the same variables for all inputs\n",
    "def two_hidden_layers(x):\n",
    "    assert x.shape.as_list() == [200,100]\n",
    "    w1 = tf.get_variable(\"h1_weights\", [100,50], initializer=tf.random_normal_initializer())\n",
    "    b1 = tf.get_variable(\"h1_bias\", [50], initializer=tf.constant_initializer(0.0))\n",
    "    h1 = tf.matmul(x, w1) + b1\n",
    "    assert h1.shape.as_list() == [200,50]\n",
    "    \n",
    "    w2 = tf.get_variable(\"h2_weights\", [50,10], initializer=tf.random_normal_initializer())\n",
    "    b2 = tf.get_variable(\"h2_bias\", [10], initializer=tf.constant_initializer(0.0))\n",
    "    logits = tf.matmul(h1, w2) + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Variable h1_weights already exists'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run into error\n",
    "'''Variable h1_weights already exists'''\n",
    "##two_hidden_layers(x1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## only works for the 1st run\n",
    "#with tf.variable_scope('two_layers') as scope:\n",
    "#    logits1 = two_hidden_layers(x1)\n",
    "#    scope.reuse_variables()\n",
    "#    logits2 = two_hidden_layers(x2)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 18.62500191  14.10765076 -50.07489777 ...,  23.15142441 -13.62567902\n",
      "   22.8212204 ]\n",
      " [ 32.68597794 -13.48661995 -48.57907486 ...,  41.37913513  -3.57254314\n",
      "   29.26268578]\n",
      " [ 15.79287338   2.96079016 -19.50897026 ...,  52.17253113   3.56869173\n",
      "   47.48681259]\n",
      " ..., \n",
      " [  7.77192831  11.17233181 -23.49403954 ...,  32.69718933 -19.7682724\n",
      "   17.48107338]\n",
      " [ 12.27888203 -26.80703163 -27.26577568 ...,   1.05881214   2.46263885\n",
      "   20.03494072]\n",
      " [ 34.54281616  -8.83656883 -21.80001259 ...,  43.43499374 -11.01299953\n",
      "   33.83807373]]\n",
      "[[ 49.05068588 -10.76355171  -5.69057655 ...,  43.03948593 -39.44934845\n",
      "   44.85665512]\n",
      " [ 44.62335587  18.63925552 -17.31506157 ...,  22.98013115 -14.63524246\n",
      "   42.42957306]\n",
      " [ 31.48861122 -12.94964504 -42.5217247  ...,  37.2021904   10.60235596\n",
      "    7.83469248]\n",
      " ..., \n",
      " [ 36.46055222 -16.90989494 -60.32016754 ...,  18.06630707 -37.39080811\n",
      "    4.99881744]\n",
      " [ 28.52477455  -0.13829756 -42.36177826 ...,  58.32488251  -7.31718969\n",
      "    4.5991497 ]\n",
      " [ 14.90968132 -30.45858574 -41.17512512 ...,  45.50582886 -27.20837593\n",
      "   16.31186867]]\n"
     ]
    }
   ],
   "source": [
    "## when have more layers that are similar in structure\n",
    "\n",
    "def fully_connected(x, output_dim, scope):\n",
    "    with tf.variable_scope(scope) as scope:\n",
    "        tf.set_random_seed(1)\n",
    "        w = tf.get_variable('weights', [x.shape[1], output_dim], initializer=tf.random_normal_initializer())\n",
    "        b = tf.get_variable(\"bias\", [output_dim], initializer=tf.constant_initializer(0.0))\n",
    "        return tf.matmul(x, w) + b\n",
    "\n",
    "input = tf.placeholder(tf.float32, shape=[200,100])\n",
    "h1 = fully_connected(input, 50, 'h1')\n",
    "logits = fully_connected(h1, 10, 'h2')\n",
    "\n",
    "np.random.seed(1)\n",
    "x1 = np.random.rand(200, 100)\n",
    "x2 = np.random.rand(200, 100)\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    with tf.variable_scope('two_layers') as scope:\n",
    "        print(sess.run(logits, feed_dict={input:x1}))\n",
    "        scope.reuse_variables()\n",
    "        print(sess.run(logits, feed_dict={input:x2}))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
