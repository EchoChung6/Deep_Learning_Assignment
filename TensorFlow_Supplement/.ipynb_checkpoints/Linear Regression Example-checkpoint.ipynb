{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression Example\n",
    "\n",
    "* Author: Yingying ZHONG\n",
    "* data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.framework import ops\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medv</th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>b</th>\n",
       "      <th>lstat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.64</td>\n",
       "      <td>-0.864370</td>\n",
       "      <td>-0.370370</td>\n",
       "      <td>0.155011</td>\n",
       "      <td>0.283213</td>\n",
       "      <td>-0.461594</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.583969</td>\n",
       "      <td>-0.425532</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.820640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "      <td>-0.999528</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.515396</td>\n",
       "      <td>-0.654321</td>\n",
       "      <td>0.095995</td>\n",
       "      <td>0.565396</td>\n",
       "      <td>-0.302076</td>\n",
       "      <td>-0.913043</td>\n",
       "      <td>-0.790076</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.591060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>-0.999529</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.515396</td>\n",
       "      <td>-0.654321</td>\n",
       "      <td>0.388772</td>\n",
       "      <td>0.198764</td>\n",
       "      <td>-0.302076</td>\n",
       "      <td>-0.913043</td>\n",
       "      <td>-0.790076</td>\n",
       "      <td>0.106383</td>\n",
       "      <td>0.979475</td>\n",
       "      <td>-0.873068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>-0.999414</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.873900</td>\n",
       "      <td>-0.699588</td>\n",
       "      <td>0.317111</td>\n",
       "      <td>-0.116375</td>\n",
       "      <td>-0.102911</td>\n",
       "      <td>-0.826087</td>\n",
       "      <td>-0.866412</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>0.988552</td>\n",
       "      <td>-0.933223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>36</td>\n",
       "      <td>-0.998590</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>-0.873900</td>\n",
       "      <td>-0.699588</td>\n",
       "      <td>0.374210</td>\n",
       "      <td>0.056643</td>\n",
       "      <td>-0.102911</td>\n",
       "      <td>-0.826087</td>\n",
       "      <td>-0.866412</td>\n",
       "      <td>0.297872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.801325</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   medv      crim    zn     indus       nox        rm       age       dis  \\\n",
       "0    24 -1.000000 -0.64 -0.864370 -0.370370  0.155011  0.283213 -0.461594   \n",
       "1    21 -0.999528 -1.00 -0.515396 -0.654321  0.095995  0.565396 -0.302076   \n",
       "2    34 -0.999529 -1.00 -0.515396 -0.654321  0.388772  0.198764 -0.302076   \n",
       "3    33 -0.999414 -1.00 -0.873900 -0.699588  0.317111 -0.116375 -0.102911   \n",
       "4    36 -0.998590 -1.00 -0.873900 -0.699588  0.374210  0.056643 -0.102911   \n",
       "\n",
       "        rad       tax   ptratio         b     lstat  \n",
       "0 -1.000000 -0.583969 -0.425532  1.000000 -0.820640  \n",
       "1 -0.913043 -0.790076  0.106383  1.000000 -0.591060  \n",
       "2 -0.913043 -0.790076  0.106383  0.979475 -0.873068  \n",
       "3 -0.826087 -0.866412  0.297872  0.988552 -0.933223  \n",
       "4 -0.826087 -0.866412  0.297872  1.000000 -0.801325  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "names =  ['medv', 'crim', 'zn', 'indus', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'b', 'lstat']\n",
    "data = pd.read_csv('data/housing_scale.csv', header=None, names=names)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing the data\n",
    "def split_data(data):\n",
    "    np.random.seed(1)\n",
    "    N = len(data)\n",
    "    idx = np.arange(N)\n",
    "    np.random.shuffle(idx)\n",
    "    train_idx = idx[:int(N/2)]\n",
    "    test_idx = idx[int(N/2):]\n",
    "\n",
    "    X_train = data.loc[train_idx].drop('medv', axis=1)\n",
    "    t_train = data.loc[train_idx]['medv']\n",
    "    X_test = data.loc[test_idx].drop('medv', axis=1)\n",
    "    t_test = data.loc[test_idx]['medv']\n",
    "\n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(253, 12) (253, 1)\n",
      "253 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Yingying/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:4: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/Yingying/anaconda/envs/tensorflow/lib/python3.6/site-packages/ipykernel_launcher.py:6: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "X_train, t_train, X_test, t_test = split_data(data)\n",
    "m = X_train.shape[0]\n",
    "n = X_train.shape[1]\n",
    "t_train = t_train.reshape(m,1)\n",
    "m_test = t_test.shape[0]\n",
    "t_test = t_test.reshape(m_test,1)\n",
    "print(X_train.shape, t_train.shape)\n",
    "print(m,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_placeholder(n):\n",
    "    \"\"\"\n",
    "    Creates the placeholders for the tensorflow session.\n",
    "    \n",
    "    Arguments:\n",
    "    n -- scalar, number of features\n",
    "    \n",
    "    Returns:\n",
    "    X -- placeholder for the data input, of shape [None, n] and dtype \"float\"\n",
    "    Y -- placeholder for the input labels, of shape [None, 1] and dtype \"float\"\n",
    "    \n",
    "    Tips:\n",
    "    - use None to allow flexibility on the number of examples.\n",
    "      In fact, the number of examples during test/train is different.\n",
    "    \"\"\"\n",
    "    X = tf.placeholder(tf.float32, [None, n])\n",
    "    Y = tf.placeholder(tf.float32, [None, 1])\n",
    "    \n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters():\n",
    "    \"\"\"\n",
    "    W: [12,1]\n",
    "    b: a scaler\n",
    "    \"\"\"\n",
    "    tf.set_random_seed(1)\n",
    "    \n",
    "    W = tf.get_variable(\"W\", [12,1], initializer = tf.contrib.layers.xavier_initializer(seed = 1))\n",
    "    b = tf.get_variable(\"w\", [1], initializer = tf.zeros_initializer())\n",
    "    \n",
    "    # W = tf.Variable(tf.truncated_normal([12, 1], mean=0.0, stddev=1.0, dtype=tf.float32))\n",
    "    # b = tf.Variable(tf.zeros([1]))\n",
    "    \n",
    "    parameters = {\"W\" : W,\n",
    "                  \"b\" : b}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def liner_function(X, parameters):\n",
    "    \"\"\"\n",
    "    Implement linear function Y = WX + b\n",
    "    \"\"\"\n",
    "    # Retrieve parameters from the dictionary parameters\n",
    "    W = parameters[\"W\"]\n",
    "    b = parameters[\"b\"]\n",
    "    \n",
    "    # Construct a linear model\n",
    "    pred = tf.add(tf.matmul(X, W), b)\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.reduce_sum()\n",
    "\n",
    "https://tensorflow.google.cn/api_docs/python/tf/reduce_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(pred, Y):\n",
    "    \"\"\"\n",
    "    Compute the mean square error\n",
    "    \n",
    "    Argument:\n",
    "    pred - the output of linear function\n",
    "    Y - true labels vector placeholder\n",
    "    \n",
    "    Return\n",
    "    the cost \n",
    "    \"\"\"\n",
    "    return tf.reduce_sum(tf.pow(pred - Y, 2)) / (2 * m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_regression_model(X_train, t_train, X_test, t_test, learning_rate = 0.01, \n",
    "                            num_epochs = 1000, display_step = 50, print_cost = True):\n",
    "    \n",
    "    ops.reset_default_graph()                         # to be able to rerun the model without overwriting tf variables\n",
    "    tf.set_random_seed(1)                             # to keep consistent results\n",
    "    seed = 3                                          # to keep consistent results\n",
    "    \n",
    "    \n",
    "    (m, n) = X_train.shape\n",
    "    costs = []\n",
    "    \n",
    "    X, Y = create_placeholder(n)\n",
    "    parameters = initialize_parameters()\n",
    "    pred = liner_function(X, parameters)\n",
    "    cost = compute_cost(pred, Y)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "    \n",
    "    # Initialize all the variables\n",
    "    init = tf.global_variables_initializer()\n",
    "    \n",
    "    # Start the session to compute the tensorflow graph\n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        # Run the initialization\n",
    "        sess.run(init)\n",
    "        \n",
    "        # Do the training loop\n",
    "        for epoch in range(num_epochs):\n",
    "            _, epoch_cost = sess.run([optimizer, cost], feed_dict={X: X_train, Y: t_train})\n",
    "            \n",
    "            if print_cost == True and epoch % 100 == 0:\n",
    "                print (\"Cost after epoch %i : %f\" % (epoch, epoch_cost))\n",
    "            if print_cost == True and epoch % 5 == 0:\n",
    "                costs.append(epoch_cost)\n",
    "    \n",
    "        # plot the cost\n",
    "        plt.plot(np.squeeze(costs)) # Remove single-dimensional entries from the shape of costs\n",
    "        plt.ylabel('cost')\n",
    "        plt.xlabel('iterations(per 5 epoches)')\n",
    "        plt.title(\"Learning rate =\" + str(learning_rate))\n",
    "        plt.show()\n",
    "        \n",
    "        # save the parameters in a variable\n",
    "        parameters = sess.run(parameters)\n",
    "        print (\"Parameters have been trained!\")\n",
    "        \n",
    "        # evaluation metric: the difference between prediction and true price is less than 5\n",
    "        correct_prediction = (tf.abs(pred - Y) < 5) # return a boolean vactor i.e[1,0,1,1,...]\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\")) # the mean reflects the accuracy\n",
    "        \n",
    "        print (\"Train Accuracy:\", accuracy.eval({X: X_train, Y: t_train}))\n",
    "        print (\"Test Accuracy:\", accuracy.eval({X: X_test, Y: t_test}))\n",
    "      \n",
    "        return parameters\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after epoch 0 : 277.802246\n",
      "Cost after epoch 100 : 28.478800\n",
      "Cost after epoch 200 : 23.638777\n",
      "Cost after epoch 300 : 20.332161\n",
      "Cost after epoch 400 : 18.000671\n",
      "Cost after epoch 500 : 16.335632\n",
      "Cost after epoch 600 : 15.131363\n",
      "Cost after epoch 700 : 14.248716\n",
      "Cost after epoch 800 : 13.592731\n",
      "Cost after epoch 900 : 13.098104\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x117273dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters have been trained!\n",
      "Train Accuracy: 0.790514\n",
      "Test Accuracy: 0.814229\n",
      "W : [[-6.61955118]\n",
      " [-0.35098591]\n",
      " [-1.97868288]\n",
      " [-2.42378449]\n",
      " [ 7.82025957]\n",
      " [ 0.36531568]\n",
      " [-5.42600298]\n",
      " [ 1.68095303]\n",
      " [-1.03731382]\n",
      " [-4.91519117]\n",
      " [ 2.80296731]\n",
      " [-8.90307236]] \n",
      "b : [ 6.87906837] \n"
     ]
    }
   ],
   "source": [
    "parameters = linear_regression_model(X_train, t_train, X_test, t_test)\n",
    "print(\"W : %s \" % parameters[\"W\"])\n",
    "print(\"b : %s \" % parameters[\"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tfkernel",
   "language": "python",
   "name": "tfkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
